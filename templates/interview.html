<!DOCTYPE html>
<html lang="en" class="dark">`
    <title>AI Mock Interview</title>
    <script src="https://cdn.tailwindcss.com"></script>
</head>

<body class="bg-gray-900 text-white flex justify-center items-center h-screen">
    <input type="hidden" name="csrfmiddlewaretoken" value="{{ csrf_token }}"> <!-- CSRF Token -->

    <div class="bg-gray-800 p-6 rounded-lg shadow-lg w-3/4 flex">
        <!-- Left Side: Interview Question -->
        <div class="w-1/2 p-4">
            <h2 class="text-2xl font-semibold mb-4">Interview Question</h2>
            <p id="question" class="text-lg text-gray-300">Loading question...</p>

            <button onclick="startRecording()" id="startBtn"
                class="bg-green-500 hover:bg-green-700 text-white font-bold py-2 px-4 rounded mt-4">
                Start Recording
            </button>
            <button onclick="stopRecording()" id="stopBtn"
                class="bg-red-500 hover:bg-red-700 text-white font-bold py-2 px-4 rounded mt-4 hidden">
                Stop Recording
            </button>
            <button onclick="terminateTest()"
                class="bg-gray-600 hover:bg-gray-700 text-white font-bold py-2 px-4 rounded mt-4">
                Finish Interview
            </button>

            <h3 class="text-xl font-semibold mt-4">Recorded Answer:</h3>
            <p id="transcript" class="text-gray-300 mt-2">...</p>
        </div>

        <!-- Right Side: Webcam -->
        <div class="w-1/2 flex justify-center items-center">
            <video id="webcam" class="rounded-lg shadow-lg w-full" autoplay></video>
        </div>
    </div>

    <script>
        let mediaRecorder;
        let transcriptElem = document.getElementById("transcript");
        let questions = [];
        let currentQuestionIndex = 0;
        let userAnswers = [];

        let recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
        recognition.continuous = false;
        recognition.lang = 'en-US';

        async function loadQuestions() {
            try {
                let response = await fetch("/api/start-interview/");
                let data = await response.json();
                questions = data.questions;
                document.getElementById("question").textContent = questions[currentQuestionIndex] || "No questions available.";
            } catch (error) {
                console.error("Error fetching questions:", error);
            }
        }

        async function startRecording() {
            try {
                document.getElementById("startBtn").classList.add("hidden");
                document.getElementById("stopBtn").classList.remove("hidden");

                let stream = await navigator.mediaDevices.getUserMedia({ video: true, audio: true });
                document.getElementById("webcam").srcObject = stream;

                mediaRecorder = new MediaRecorder(stream);
                mediaRecorder.start();

                recognition.start();

                recognition.onresult = (event) => {
                    let transcript = Array.from(event.results)
                        .map(result => result[0].transcript)
                        .join('');
                    transcriptElem.textContent = transcript;
                    userAnswers[currentQuestionIndex] = {
                        question: questions[currentQuestionIndex],
                        answer: transcript
                    };
                };

                recognition.onerror = (event) => {
                    console.error("Speech recognition error:", event.error);
                    alert("Speech recognition failed. Please try again.");
                };
            } catch (error) {
                console.error("Error accessing media devices:", error);
                alert("Please allow microphone and webcam access to proceed.");
            }
        }

        async function stopRecording() {
            document.getElementById("startBtn").classList.remove("hidden");
            document.getElementById("stopBtn").classList.add("hidden");

            mediaRecorder.stop();
            recognition.stop();

            if (currentQuestionIndex < questions.length - 1) {
                currentQuestionIndex++;
                document.getElementById("question").textContent = questions[currentQuestionIndex];
                transcriptElem.textContent = "...";
            } else {
                alert("Interview completed! Click 'Finish Interview' to evaluate your answers.");
            }
        }

        async function terminateTest() {
            alert("Interview completed! Evaluating your answers...");
            
            let csrfToken = document.querySelector('[name=csrfmiddlewaretoken]').value;
        
            console.log("User Answers before sending:", JSON.stringify(userAnswers, null, 2)); // Debugging
        
            try {
                let response = await fetch("/api/evaluate-interview/", {
                    method: "POST",
                    headers: {
                        "Content-Type": "application/json",
                        "X-CSRFToken": csrfToken
                    },
                    body: JSON.stringify({ answers: userAnswers })
                });
        
                if (!response.ok) {
                    throw new Error(`HTTP error! Status: ${response.status}`);
                }
        
                let data = await response.json();
                console.log('Final Evaluation Response:', data);
        
                if (data.success) {
                    window.location.href = "/result/";
                } else {
                    alert("Evaluation failed. Please try again.");
                }
            } catch (error) {
                console.error("Error during final evaluation:", error);
                alert("Something went wrong! Check the console for details.");
            }
        }

        loadQuestions();
    </script>
</body>

</html>
